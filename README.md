# Machine Learning

## 1. Foundations (Prerequisites and Introduction)

### Introduction to Machine Learning
1. What is ML? ([Lecture 1](notes/Lecture-1.pdf))
2. Supervised vs. Unsupervised vs. Reinforcement Learning ([Lecture 2](notes/Lecture-2.pdf))
3. Applications of Machine Learning ([Activity 1](exercises/Activity-1.pdf))
4. Basic ML Terminology ([Lecture 3](notes/Lecture-3.pdf))

### Python for Machine Learning
1. NumPy for numerical operations ([Numpy essentials](lab/01_numpy.md))
2. Pandas for data manipulation ([Pandas essentials](lab/02_pandas.md))
3. Matplotlib/Seaborn for data visualization ([Matplotlib essentials](lab/03_mathplotlib.md))
4. Scikit-learn basics for loading datasets, splitting data ([Scikit-learn essentials](lab/04_sklearn.md))

### Overview of Mathematical Foundations
1. Linear Algebra ([Importance of LA in ML](notes/Lecture-4.pdf))
2. Probability & Statistics ([Importance of Probability & Statistics in ML](notes/Lecture-5.pdf))
3. Calculus ([Importance of Calculus in ML](notes/Lecture-6.pdf))

## 2. Supervised Learning - Regression

### Data Preprocessing and Exploration
1. Handling missing values ([Reading](https://www.geeksforgeeks.org/machine-learning/managing-missing-data-in-linear-regression/)]
2. Feature scaling - standardization, normalization - ([Reading](https://www.geeksforgeeks.org/machine-learning/ml-feature-scaling-part-2/))
3. One-hot encoding for categorical features ([Reading](https://www.geeksforgeeks.org/machine-learning/ml-one-hot-encoding/))
4. Exploratory Data Analysis (EDA)

### Linear Regression
1. Simple Linear Regression ([Mathematical intuition](https://www.youtube.com/watch?v=OM1dtIt0VNo))
2. Cost function (Mean Squared Error - MSE)
3. Gradient Descent algorithm ([Mathematical intuition](https://youtu.be/9H-s5cQ1iBk?si=um9J605sChHFYH6b))
4. Multiple Linear Regression ([Geeks-for-geeks](https://www.geeksforgeeks.org/machine-learning/ml-linear-regression/))
5. Assumptions of Linear Regression

### Model Evaluation for Regression
1. R^2, Adjusted R^2
2. MAE, MSE, RMSE
3. Overfitting and Underfitting
4. Bias-Variance Tradeoff
5. Cross-validation (k-fold, leave-one-out)

### Regularization
1. Ridge Regression (L2 regularization) ([Ridge](https://www.geeksforgeeks.org/machine-learning/implementation-of-ridge-regression-from-scratch-using-python/))
2. Lasso Regression (L1 regularization) ([Lasso](https://www.geeksforgeeks.org/machine-learning/implementation-of-lasso-regression-from-scratch-using-python/))
3. Elastic Net

### Lab Activity
1. Implementation ([Coding step-by-step](Coding_Linear_Regression.md))
2. Lab Assignment ([Lab Activity](lab/05_lrimpl.md))
